{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b61dcc3-4774-4fe8-839e-d8f714bc38b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e715a-0854-4c4c-b45a-4aca1fba2132",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1674d6f-595b-4b28-a1e9-fa139a0715ae",
   "metadata": {},
   "source": [
    "#### Loading Tweeteval dataset from huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d6b53dd-9d20-478a-8c53-388804e49a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('tweet_eval', 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d00e4-fae8-4fe8-80f1-082ac5d562e4",
   "metadata": {},
   "source": [
    "#### Inspecting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db64551e-0743-491f-bb31-c930a53c1ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 45615\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 12284\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbddcee1-a952-485f-89da-b4f9a379a1bf",
   "metadata": {},
   "source": [
    "#### Convert to pandas DataFrames for easier handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287901bc-75e5-4e01-b83f-0d4900927a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(dataset['train'])\n",
    "val_df = pd.DataFrame(dataset['validation'])\n",
    "test_df = pd.DataFrame(dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d7bd2-3009-4921-a45f-cdc354c83539",
   "metadata": {},
   "source": [
    "#### Map labels to sentiment strings for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4527ca79-7e6a-4a6e-b1ab-14846c765a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "train_df['label_name'] = train_df['label'].map(label_mapping)\n",
    "val_df['label_name'] = val_df['label'].map(label_mapping)\n",
    "test_df['label_name'] = test_df['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a119735-7e88-44a8-b53d-c270ae728543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label label_name\n",
      "0  \"QT @user In the original draft of the 7th boo...      2   positive\n",
      "1  \"Ben Smith / Smith (concussion) remains out of...      1    neutral\n",
      "2  Sorry bout the stream last night I crashed out...      1    neutral\n",
      "3  Chase Headley's RBI double in the 8th inning o...      1    neutral\n",
      "4  @user Alciato: Bee will invest 150 million in ...      2   positive\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26550e02-c464-4a00-9b04-7fc9a44ae283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_name\n",
       "neutral     20673\n",
       "positive    17849\n",
       "negative     7093\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts = train_df['label_name'].value_counts()\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af5a5a3-a216-4205-a4fc-8cabbb3c2b74",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b1af6-32ff-402c-92e8-35cf946cf226",
   "metadata": {},
   "source": [
    "#### Defining preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda075e3-106f-4a44-8a1c-c4f48874b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)     # Remove @mentions\n",
    "    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'#', '', text)                  # Remove hashtag symbol\n",
    "    text = re.sub(r'\\n', ' ', text)                # Remove line breaks\n",
    "    text = re.sub(r'&amp;', '&', text)             # Replace HTML ampersand\n",
    "    text = re.sub(r'[^a-zA-Z\\'\\s]', '', text)      # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()       # Remove extra whitespace\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c7e5c-cbc0-4476-85e7-8d4754a0adba",
   "metadata": {},
   "source": [
    "#### Applying function to train, validation and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "674e4313-0bb7-4b8c-bbf2-e96961921759",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['clean_text'] = train_df['text'].apply(clean_tweet)\n",
    "val_df['clean_text'] = val_df['text'].apply(clean_tweet)\n",
    "test_df['clean_text'] = test_df['text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80537f6f-11bd-4d47-9154-7073aee4408e",
   "metadata": {},
   "source": [
    "#### Initialize tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21f8393-4001-4465-9f36-f71539a673d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdc9d6c-6c60-4d95-bf7e-dd417953f92c",
   "metadata": {},
   "source": [
    "# Prepare Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60de77a0-5dc1-4a07-9dc0-4da5eb9e11f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 64\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,        # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,                # Truncate longer sentences\n",
    "            padding='max_length',           # Pad shorter sentences\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),        # Convert from [1, max_len] to [max_len]\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49586fa6-2555-4821-a47d-74073c00cf22",
   "metadata": {},
   "source": [
    "#### Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6d27e9d-7658-498d-b819-7c55857d7211",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(\n",
    "    texts=train_df['clean_text'].values,\n",
    "    labels=train_df['label'].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "val_dataset = SentimentDataset(\n",
    "    texts=val_df['clean_text'].values,\n",
    "    labels=val_df['label'].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "test_dataset = SentimentDataset(\n",
    "    texts=test_df['clean_text'].values,\n",
    "    labels=test_df['label'].values,\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f334b0-a1f7-44df-aa42-fbd7c1770491",
   "metadata": {},
   "source": [
    "#### Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2fa4abf-b3a8-44e1-9df9-f90e370052d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922a1416-6a67-4ede-b520-532a26d53f47",
   "metadata": {},
   "source": [
    "# Setup Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33020e8-c836-464f-b895-d540e3e50e7c",
   "metadata": {},
   "source": [
    "#### Load Pre-Trained Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64c9d98d-8aca-4928-85ac-e294fdbb5a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=3,   # Multi-class classification (negative, neutral, positive)\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b271d6b-58f4-4441-bba0-be1545396226",
   "metadata": {},
   "source": [
    "#### Set Device to CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "467c6ae8-2a87-4d81-919d-a3d19d8d9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc5b56a5-cd65-4685-abe3-9c692480de24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e08cc6-0492-4674-aa12-4e76f483c2b0",
   "metadata": {},
   "source": [
    "#### Define optimizer and schedular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60e7515b-9997-48df-a882-c0f26f0290bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "\n",
    "# Calculate total steps\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "EPOCHS = 3\n",
    "total_steps = len(train_dataloader) * EPOCHS\n",
    "\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,             # Default value in transformers\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b69b19-c0b0-41a0-a39d-66e80c443af3",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf13e51-8b94-45c1-b6a4-e4a1a08c87fb",
   "metadata": {},
   "source": [
    "#### Define training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40ce0b49-6ff4-472d-9d5e-e8b72ddbe6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    n_examples\n",
    "):\n",
    "    model = model.train()\n",
    "    \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Prevent exploding gradients\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ecab26-5578-4708-b657-bd84b6f749a0",
   "metadata": {},
   "source": [
    "#### Define validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a8ffc5b-83e6-4fc7-9b8b-3965ac4bf649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(\n",
    "    model,\n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    n_examples\n",
    "):\n",
    "    model = model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1191636-a23f-466d-b6b7-2a44c8988bfc",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe50e0d-9704-4aa2-a7f9-c70b7cb28b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_dataset)\n",
    "    )\n",
    "    \n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_dataloader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_dataset)\n",
    "    )\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    \n",
    "    print(f'Train loss {train_loss:.4f} accuracy {train_acc:.4f}')\n",
    "    print(f'Val   loss {val_loss:.4f} accuracy {val_acc:.4f}')\n",
    "    print(f'Epoch time: {epoch_time // 60:.0f}m {epoch_time % 60:.0f}s')\n",
    "    print()\n",
    "    \n",
    "    history['train_acc'].append(train_acc.cpu())\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc.cpu())\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    # Save the best model\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880294b8-7842-4368-8b77-edee295f39c2",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f96a33e-f6b8-47c4-880b-85620bb16962",
   "metadata": {},
   "source": [
    "#### Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c46981-e880-4e84-b1ac-f799dde56c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_state.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465e2723-6e23-4ecc-ab36-c107a4aa948b",
   "metadata": {},
   "source": [
    "#### Define prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ad6ef-eb20-4144-b707-6c55286b36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    model = model.eval()\n",
    "    \n",
    "    texts = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    real_values = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            texts.extend(batch['text'])\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu())\n",
    "            prediction_probs.extend(probs.cpu())\n",
    "            real_values.extend(labels.cpu())\n",
    "            \n",
    "    predictions = torch.stack(predictions)\n",
    "    prediction_probs = torch.stack(prediction_probs)\n",
    "    real_values = torch.stack(real_values)\n",
    "    \n",
    "    return texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54290220-54b8-43d4-8f9a-2541bf192089",
   "metadata": {},
   "source": [
    "#### Generate Classification Report on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb2693-4f0c-480a-b17c-ea3eac6ff226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "label_names = ['negative', 'neutral', 'positive']\n",
    "\n",
    "texts, y_pred, y_pred_probs, y_true = get_predictions(model, val_dataloader)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d9ba7f-6aa1-47f0-8088-89a07892e28a",
   "metadata": {},
   "source": [
    "#### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86affc8e-c57b-4f0f-8a63-c3c9943cd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_test, y_pred_test, y_pred_probs_test, y_true_test = get_predictions(model, test_dataloader)\n",
    "\n",
    "print('Test Set Evaluation:')\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=label_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
